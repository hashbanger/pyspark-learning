{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/05 15:00:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/02/05 15:00:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setMaster(\"local[2]\").setAppName(\"DegreesOfSeparation\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The characters we wish to find the degree of separation between:\n",
    "startCharacterID = 5306 # SpiderMan\n",
    "targetCharacterID = 14 # adam 3,031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our accumulator, used to signal when we find the target character during our BFS traversal.\n",
    "hitCounter = sc.accumulator(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToBFS(line):\n",
    "    fields = line.split()\n",
    "    heroID = int(fields[0])\n",
    "    connections = []\n",
    "    for connection in fields[1:]:\n",
    "        connections.append(int(connection))\n",
    "\n",
    "    color = \"WHITE\"\n",
    "    distance = 9999\n",
    "\n",
    "    if (heroID == startCharacterID):\n",
    "        color = \"GRAY\"\n",
    "        distance = 0\n",
    "\n",
    "    return (heroID, (connections, distance, color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createStartingRdd():\n",
    "    inputFile = sc.textFile(\"resources/Marvel-Graph\")\n",
    "    return inputFile.map(convertToBFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfsMap(node):\n",
    "    characterID = node[0]\n",
    "    data = node[1]\n",
    "    connections = data[0]\n",
    "    distance = data[1]\n",
    "    color = data[2]\n",
    "\n",
    "    results = []\n",
    "    # if this node needs to be expanded\n",
    "    if (color == \"GRAY\"):\n",
    "        for connection in connections:\n",
    "            newCharacterID = connection\n",
    "            newDistance = distance + 1\n",
    "            newColor = \"GRAY\"\n",
    "            if (targetCharacterID == connection):\n",
    "                hitCounter.add(1)\n",
    "\n",
    "            newEntry = (newCharacterID, ([], newDistance, newColor))\n",
    "            results.append(newEntry)\n",
    "        \n",
    "        # we've processed this node, so color it black\n",
    "        color = \"BLACK\"\n",
    "\n",
    "    # emitting the input node so we don't lost it.\n",
    "    results.append((characterID, (connections, distance, color)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfsReduce(data1, data2):\n",
    "    edges1 = data1[0]\n",
    "    edges2 = data2[0]\n",
    "\n",
    "    distance1 = data1[1]\n",
    "    distance2 = data2[1]\n",
    "\n",
    "    color1 = data1[2]\n",
    "    color2 = data2[2]\n",
    "\n",
    "    distance = 9999\n",
    "    color = color1\n",
    "    edges = []\n",
    "\n",
    "    # see if one is the original node with its connections, if so preserve them\n",
    "    if (len(edges1) > 0):\n",
    "        edges.extend(edges1)\n",
    "    if (len(edges2) > 0):\n",
    "        edges.extend(edges2)\n",
    "\n",
    "    # preserve minimum distance\n",
    "    if (distance1 < distance):\n",
    "        distance = distance1\n",
    "    \n",
    "    if (distance2 < distance):\n",
    "        distance = distance2\n",
    "\n",
    "    # preserve darkest color\n",
    "    if (color1 == \"WHITE\" and (color2 == \"GRAY\" or color2 == \"BLACK\")):\n",
    "        color = color2\n",
    "\n",
    "    if (color1 == \"GRAY\" and color2 == \"BLACK\"):\n",
    "        color = color2\n",
    "\n",
    "    if (color2 == \"WHITE\" and (color1 == \"GRAY\" or color1 == \"BLACK\")):\n",
    "        color = color1\n",
    "\n",
    "    if (color2 == \"GRAY\" and color1 == \"BLACK\"):\n",
    "        color = color1\n",
    "\n",
    "    return (edges, distance, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main program here:\n",
    "iterationRdd = createStartingRdd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BFS iteration# 1\n",
      "Preprocessing 8330 values.\n",
      "Hit the target character! From 1 different direction(s).\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(0, 10):\n",
    "    print(\"Running BFS iteration# \" + str(iteration+1))\n",
    "\n",
    "    # creating new vertices as needed to darken or reduce distances in the \n",
    "    # reduce stage. If we encounter the node we're looking for as a GRAY node,\n",
    "    # increment our accumulator to signal that we're done.\n",
    "    mapped = iterationRdd.flatMap(bfsMap)\n",
    "\n",
    "    # note thta mappend.count() action here forces the RDD to be evaluated, and \n",
    "    # that's that only reason our accumulator is actually updated.\n",
    "    print(\"Preprocessing \" + str(mapped.count()) + \" values.\")\n",
    "\n",
    "    if (hitCounter.value > 0):\n",
    "        print(\"Hit the target character! From \" + str(hitCounter.value)\\\n",
    "            + \" different direction(s).\")\n",
    "        break\n",
    "\n",
    "    # reducer combined data for each character ID, preserving the darkest color and shortest path.\n",
    "    iterationRdd = mapped.reduceByKey(bfsReduce)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecac7a151c09b8456edd2abfdaf540e09fdadf88940418019d9e70d1d7653a93"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('spark_test-8u_MymxW': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
